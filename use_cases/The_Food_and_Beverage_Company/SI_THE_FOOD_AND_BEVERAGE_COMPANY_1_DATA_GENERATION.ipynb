{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ce5d2e-5494-4bd6-830b-29a85792de57",
   "metadata": {
    "language": "python",
    "name": "PACKAGE_INSTALLS"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet --root-user-action=ignore faker swifter coqui-tts pydub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7084097-d978-4655-970d-72def5351d4c",
   "metadata": {
    "collapsed": false,
    "name": "IMPORTS1"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "IMPORTS2"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "from data_generation.data_generator import DataGenerator\n",
    "from data_generation.text_to_speech import TextToSpeech\n",
    "\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1fec4b-2f02-4b8e-bdcd-a5288bbfbddb",
   "metadata": {
    "collapsed": false,
    "name": "DATA_GENERATION1"
   },
   "source": [
    "# Data Generation\n",
    "\n",
    "The classes `DataGenerator` and `TextToSpeech` generates all data required for this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e6038f-6eaf-4c84-ab92-e762e21774e8",
   "metadata": {
    "language": "python",
    "name": "DATA_GENERATION2"
   },
   "outputs": [],
   "source": [
    "# Structured Data\n",
    "data_generator = DataGenerator(session)\n",
    "data_generator.load_configuration()\n",
    "data_generator.generate_data(start_date='2024-01-01', end_date='2025-07-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811ea1a7-8595-4b68-8327-0ff0b063da2b",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": [
    "# Unstructured Data \n",
    "tts_generator = TextToSpeech(\n",
    "    model='tts_models/multilingual/multi-dataset/xtts_v2', \n",
    "    voices='data_generation/04_audio/configuration/voices.json'\n",
    ")\n",
    "\n",
    "# load conversations from json\n",
    "recordings = json.load(open('data_generation/04_audio/configuration/call_center_recordings.json'))\n",
    "output_folder = '/call_center_recordings'\n",
    "\n",
    "# Create audio files from conversations\n",
    "tts_generator.dict_to_speech_optimized(recordings, output_folder)\n",
    "\n",
    "# Upload audio files to Snowflake stage\n",
    "session.file.put(local_file_name=f'{output_folder}/*', stage_location='@AUDIO/call_center_recordings', auto_compress=False)\n",
    "session.sql('ALTER STAGE AUDIO REFRESH').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc12ec-8915-4829-b2c6-5fcf3fcc62e5",
   "metadata": {
    "collapsed": false,
    "name": "STRCUTURED_DATA1"
   },
   "source": [
    "##  Structured Data\n",
    "The data model of this demo consists of multiple tables and views listed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a301fdaf-dfd6-4f84-ae38-59a923611e9a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "STRCUTURED_DATA2"
   },
   "outputs": [],
   "source": [
    "data_generator.dim_dates.show(n=5)\n",
    "data_generator.dim_suppliers.show()\n",
    "data_generator.dim_product_hierarchy.show(n=5)\n",
    "data_generator.dim_products.show(n=5)\n",
    "data_generator.dim_platforms.show(n=5)\n",
    "data_generator.dim_customers.show(n=5)\n",
    "data_generator.dim_dates.show(n=5)\n",
    "data_generator.fact_transactions.show(n=5)\n",
    "data_generator.fact_supplier_deliveries.show(n=5)\n",
    "data_generator.fact_daily_stock_levels.show(n=5)\n",
    "data_generator.customer_reviews.show(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75ec56-518a-4de6-8476-0776b7572e4f",
   "metadata": {
    "collapsed": false,
    "name": "UNSTRUCTURED_DATA1"
   },
   "source": [
    "## Unstructured Data\n",
    "\n",
    "This demo provides multiple unstructured datasources listed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9961da6-5921-4cca-82b1-e8fa5421daf9",
   "metadata": {
    "language": "sql",
    "name": "UNSTRUCTURED_DATA2"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM DIRECTORY(@DOCUMENTS) limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7d51ac-7fb3-402d-b43f-d4ce4f296751",
   "metadata": {
    "language": "sql",
    "name": "UNSTRUCTURED_DATA3"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM DIRECTORY(@AUDIO) limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4f5a88-252a-44f4-83e4-d5a7739e684d",
   "metadata": {
    "collapsed": false,
    "name": "cell1"
   },
   "source": [
    "# START CALL CENTER GENERATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c4dee3-18f4-4cf1-871a-71c9475cd4e9",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pydub import AudioSegment\n",
    "from TTS.api import TTS\n",
    "\n",
    "class TextToSpeech:\n",
    "    def __init__(self, model, voices):\n",
    "        os.environ[\"COQUI_TOS_AGREED\"] = \"1\"\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.tts_model = TTS(model, progress_bar=True).to(device)\n",
    "        self.voices = json.load(open(voices))\n",
    "\n",
    "    def tts_to_audiosegment(self, text, speaker):\n",
    "        \"\"\"Convert TTS directly to AudioSegment without intermediate conversions\"\"\"\n",
    "        sample_rate = self.tts_model.synthesizer.output_sample_rate\n",
    "        wav_data = self.tts_model.tts(text=text, speaker=speaker, language='en')\n",
    "        \n",
    "        # Convert to int16 for AudioSegment\n",
    "        wav_data = np.asarray(wav_data, dtype=np.float32)\n",
    "        wav_data_int16 = (wav_data * 32767).astype(np.int16)\n",
    "        \n",
    "        # Create AudioSegment directly from numpy array\n",
    "        audio_segment = AudioSegment(\n",
    "            wav_data_int16.tobytes(),\n",
    "            frame_rate=sample_rate,\n",
    "            sample_width=2,  # 2 bytes for int16\n",
    "            channels=1\n",
    "        )\n",
    "        return audio_segment\n",
    "\n",
    "    def dict_to_speech_optimized(self, voices, recordings, output_folder):\n",
    "        total_recordings = len(recordings['recordings'])\n",
    "        Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "        used_speakers = {}\n",
    "        for recording_id, recording in enumerate(recordings['recordings']):\n",
    "            print(f\"[Unstructured Data] Generating recording {recording_id+1}/{total_recordings}...\", end='\\r', flush=True)\n",
    "            \n",
    "            if np.random.random() > 0.5:\n",
    "                # customer is male, agent is female\n",
    "                customer_voice = np.random.choice(voices['male_voices'])\n",
    "                agent_voice = np.random.choice(voices['female_voices'])\n",
    "            else:\n",
    "                # customer is female, agent is male\n",
    "                customer_voice = np.random.choice(voices['female_voices'])\n",
    "                agent_voice = np.random.choice(voices['male_voices'])\n",
    "                \n",
    "            speaker_mapping = {\n",
    "                'customer': customer_voice,\n",
    "                'agent': agent_voice\n",
    "            }\n",
    "            \n",
    "            # Generate all audio segments\n",
    "            audio_segments = []\n",
    "            used_speakers[f'{recording_id:05d}'] = []\n",
    "            \n",
    "            for segment in recording['segments']:\n",
    "                text = segment['text']\n",
    "                speaker = speaker_mapping[segment['speaker']]\n",
    "                used_speakers[f'{recording_id:05d}'].append({\"text\": text, \"speaker\": speaker})\n",
    "                \n",
    "                # Direct conversion to AudioSegment\n",
    "                audio_segment = self.tts_to_audiosegment(text, speaker)\n",
    "                audio_segments.append(audio_segment)\n",
    "            \n",
    "            # Combine all segments at once\n",
    "            combined = sum(audio_segments, AudioSegment.empty())\n",
    "            combined.export(f\"{output_folder}/call_center_recording_{recording_id:05d}.wav\", format='wav')\n",
    "        \n",
    "        return used_speakers\n",
    "\n",
    "tts_generator = TextToSpeech(\n",
    "    model='tts_models/multilingual/multi-dataset/xtts_v2', \n",
    "    voices='data_generation/04_audio/configuration/voices.json'\n",
    ")\n",
    "\n",
    "# load recordings\n",
    "recordings = json.load(open('data_generation/04_audio/configuration/call_center_recordings.json'))\n",
    "output_folder = '/call_center_recordings15'\n",
    "\n",
    "used_speakers = tts_generator.dict_to_speech_optimized(voices, recordings, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe217945-109d-41ec-9746-f909187fd80e",
   "metadata": {
    "language": "sql",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE STAGE AUDIO2\n",
    "\tDIRECTORY = ( ENABLE = true ) \n",
    "\tENCRYPTION = ( TYPE = 'SNOWFLAKE_SSE' );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64159d3-5126-4221-98d3-218adc7592f8",
   "metadata": {
    "language": "python",
    "name": "cell25"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef32bc59-318c-4b53-8d93-a63cb1e193e8",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "session.file.put(local_file_name='/call_center_recordings15/*', stage_location='@AUDIO2/call_center_recordings', auto_compress=False)\n",
    "session.sql('ALTER STAGE AUDIO2 REFRESH').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b78a623-c8f8-4014-aed7-8b1316f86513",
   "metadata": {
    "language": "sql",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE TMP_SPEAKER_RECOGNITION AS \n",
    "SELECT\n",
    "  RELATIVE_PATH,\n",
    "  AI_TRANSCRIBE(TO_FILE('@AUDIO2', RELATIVE_PATH), {'timestamp_granularity': 'speaker'}) T_OUTPUT\n",
    "FROM \n",
    "  DIRECTORY('@AUDIO2')\n",
    "WHERE\n",
    "  startswith(RELATIVE_PATH, 'call_center_recordings/');\n",
    "\n",
    "SELECT * FROM TMP_SPEAKER_RECOGNITION;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e8eef6-bc2e-4ec9-9cab-72d2ea0a6f97",
   "metadata": {
    "language": "sql",
    "name": "cell19"
   },
   "outputs": [],
   "source": [
    "WITH segments AS (\n",
    "    SELECT\n",
    "      s.RELATIVE_PATH,\n",
    "      s.T_OUTPUT['audio_duration']::FLOAT AUDIO_DURATION,\n",
    "      fv.value['start']::FLOAT TRANSCRIBE_START,\n",
    "      fv.value['end']::FLOAT TRANSCRIBE_END,\n",
    "      fv.value['speaker_label']::TEXT SPEAKER_ID,\n",
    "      fv.value['text']::TEXT TRANSCRIPTION\n",
    "    FROM TMP_SPEAKER_RECOGNITION s,\n",
    "      lateral flatten(T_OUTPUT['segments']) fv\n",
    "    ORDER BY\n",
    "      s.RELATIVE_PATH,\n",
    "      TRANSCRIBE_START\n",
    "),\n",
    "ordered_transcriptions AS (\n",
    "  SELECT \n",
    "    RELATIVE_PATH,\n",
    "    TRANSCRIBE_START,\n",
    "    SPEAKER_ID,\n",
    "    TRANSCRIPTION,\n",
    "    LAG(SPEAKER_ID) OVER (PARTITION BY RELATIVE_PATH ORDER BY TRANSCRIBE_START) AS prev_speaker,\n",
    "    ROW_NUMBER() OVER (PARTITION BY RELATIVE_PATH ORDER BY TRANSCRIBE_START) AS rn\n",
    "  FROM segments\n",
    "),\n",
    "\n",
    "speaker_groups AS (\n",
    "  SELECT \n",
    "    RELATIVE_PATH,\n",
    "    TRANSCRIBE_START,\n",
    "    SPEAKER_ID,\n",
    "    TRANSCRIPTION,\n",
    "    SUM(CASE WHEN SPEAKER_ID != prev_speaker OR prev_speaker IS NULL THEN 1 ELSE 0 END) \n",
    "      OVER (PARTITION BY RELATIVE_PATH ORDER BY TRANSCRIBE_START ROWS UNBOUNDED PRECEDING) AS speaker_group\n",
    "  FROM ordered_transcriptions\n",
    "),\n",
    "\n",
    "grouped_transcriptions AS (\n",
    "  SELECT \n",
    "    RELATIVE_PATH,\n",
    "    MIN(TRANSCRIBE_START) AS group_start,\n",
    "    SPEAKER_ID,\n",
    "    speaker_group,\n",
    "    LISTAGG(TRANSCRIPTION, ' ') WITHIN GROUP (ORDER BY TRANSCRIBE_START) AS combined_transcription\n",
    "  FROM speaker_groups\n",
    "  GROUP BY RELATIVE_PATH, SPEAKER_ID, speaker_group\n",
    ")\n",
    "\n",
    "SELECT \n",
    "  RELATIVE_PATH,\n",
    "  LISTAGG(SPEAKER_ID || '\\n' || combined_transcription, '\\n---\\n') \n",
    "    WITHIN GROUP (ORDER BY group_start) AS TRANSCRIPTION_DIARIZED\n",
    "FROM grouped_transcriptions\n",
    "GROUP BY RELATIVE_PATH;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "michael.gorkow@snowflake.com",
   "authorId": "418056782820",
   "authorName": "ADMIN",
   "lastEditTime": 1755831032584,
   "notebookId": "tsfi2sm63ynp5z23cah2",
   "sessionId": "4964b91e-897d-4bd3-8de3-0d4fb0410d06"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
